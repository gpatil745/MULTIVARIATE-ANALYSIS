---
title: "LDA_Logistic Regression"
date: "2024-04-25"
output: html_document
---

```{r }
library(MASS)
library(ggplot2)
library(memisc)
library(ROCR)
library(dplyr)
library(klaR)

wdbc <- read.csv("/Users/mumba/Documents/Midterm_new.csv")
dim(wdbc)
str(wdbc)
```

#Model Development
```{r }
features <- c("Instagram", "LinkedIn", "Snapchat", "Twitter", "Whatsapp", "Youtube", "OTT", "Reddit", "Trouble_sleep", "Mood", "Tired_morning")
names(wdbc) <- c("ID", "Instagram", "LinkedIn", "Snapchat", "Twitter", "Whatsapp", "Youtube", "OTT", "Reddit", "Trouble_sleep", "Mood", "Tired_morning")
```


The process of developing the model brings clarity and context to every variable, aiding in understanding the dataset's content and significance. It ensures each variable is appropriately named, facilitating further analysis or modeling.


#Model Acceptance
```{r }
wdbc.data <- as.matrix(wdbc[,c(2:9)])
row.names(wdbc.data) <- wdbc$ID
wdbc_raw <- cbind(wdbc.data, as.numeric(as.factor(wdbc$Trouble_sleep))-1)
colnames(wdbc_raw)[9] <- "TroubleInSleep"
smp_size_raw <- floor(0.75 * nrow(wdbc_raw))
train_ind_raw <- sample(nrow(wdbc_raw), size = smp_size_raw)
train_raw.df <- as.data.frame(wdbc_raw[train_ind_raw, ])
test_raw.df <- as.data.frame(wdbc_raw[-train_ind_raw, ])
wdbc_raw.lda <- lda(formula = train_raw.df$TroubleInSleep ~ ., data = train_raw.df)
wdbc_raw.lda
summary(wdbc_raw.lda)
print(wdbc_raw.lda)
plot(wdbc_raw.lda)
```


 The prior probabilities of the two groups (0 and 1) denote the proportions of each class within the training data. Specifically, in this instance, 60% of the dataset pertains to the class indicating no sleep trouble (0), while 40% corresponds to the class indicating trouble (1).


#Model Accuracy
```{r }
wdbc_raw.lda.predict_train <- predict(wdbc_raw.lda, newdata = train_raw.df)
y<-wdbc_raw.lda.predict_train$class
wdbc_raw.lda.predict_train$x
table(y,train_raw.df$TroubleInSleep)
```


```{r }
wdbc_raw.lda.predict_test <- predict(wdbc_raw.lda, newdata = test_raw.df)
y<-wdbc_raw.lda.predict_test$class
wdbc_raw.lda.predict_test$x
table(y,test_raw.df$TroubleInSleep)
```
The accuracy is 0.867.
The accuracy is 0.833.


#Prediction
```{r }
wdbc_raw.lda.predict.posteriors <- as.data.frame(wdbc_raw.lda.predict_test$posterior)

pred <- prediction(wdbc_raw.lda.predict.posteriors[,2], test_raw.df$TroubleInSleep)
roc.perf = performance(pred, measure = "tpr", x.measure = "fpr")
auc.train <- performance(pred, measure = "auc")
auc.train <- auc.train@y.values
plot(roc.perf)
abline(a=0, b= 1)
text(x = .25, y = .65 ,paste("AUC = ", round(auc.train[[1]],3), sep = ""))
```


```{r }
plot(wdbc_raw.lda, col = as.integer(train_raw.df$TroubleInSleep))
plot(wdbc_raw.lda, dimen = 1, type = "b")
```

Here, the ROC curve is generated, and the AUC value is computed and depicted on the plot. A perfect classification is indicated by an AUC value of 1, while an AUC of 0.5 signifies random classification.

#Residual Analysis
```{r }
m <- manova(cbind(wdbc$Instagram,wdbc$LinkedIn,wdbc$Snapchat,wdbc$Twitter)~wdbc$Trouble_sleep,data=wdbc)
summary(m,test="Wilks")

summary(m,test="Pillai")

summary.aov(m)
```
The p-value of 0.09774 exceeds the commonly utilized significance level of 0.05, suggesting that this effect lacks statistical significance. Solely for Twitter, however, the p-value (0.009828) falls below 0.05, demonstrating a statistically significant impact of Trouble_sleep on Twitter usage.